{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动处理越南语没有成功翻译的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.58.1-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.8.2-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from openai) (2.8.2)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\tensorrt-llm\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.58.1-py3-none-any.whl (454 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.8.2-cp310-cp310-win_amd64.whl (204 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sniffio, python-dotenv, jiter, h11, distro, httpcore, anyio, httpx, openai\n",
      "Successfully installed anyio-4.7.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.58.1 python-dotenv-1.0.1 sniffio-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190793/190793 [00:05<00:00, 33760.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def contains_chinese(text):\n",
    "    # 使用正则表达式匹配中文字符\n",
    "    return bool(re.search(r'[\\u4e00-\\u9fff]', text))\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "original_language = \"Chinese\"\n",
    "target_language = \"Korean\"\n",
    "def generate_text(index, data):\n",
    "    if data[\"module\"] == \"Error: Connection error.\":\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in translating {original_language} to {target_language} for ERP systems. Your task is to translate markdown-formatted text from {original_language} to {target_language}. Preserving its formatting without adding extra content.\"},\n",
    "                {\"role\": \"user\", \"content\": str(data['value'])}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        return index, completion.choices[0].message.content\n",
    "    else:\n",
    "        return index, str(data[\"module\"])\n",
    "    \n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "\n",
    "filenames = [\n",
    "    r\"C:\\Users\\wangz\\Downloads\\翻译韩语从B到C列-0116.xlsx\",\n",
    "]\n",
    "for filename in filenames:\n",
    "    to_fix = pd.read_excel(filename)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        futures = {executor.submit(generate_text, index, row) for index, row in to_fix.iterrows()}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            index, output = future.result()\n",
    "\n",
    "            if output is not None:\n",
    "                to_fix.at[index, \"module\"] = output\n",
    "    # 保存最终结果到 Excel 文件\n",
    "    to_fix.to_excel(filename.replace(\".xlsx\", \"_translated.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fix.to_csv(r\"C:\\Users\\wangz\\Downloads\\未翻译词条_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fix = pd.read_excel(r\"C:\\Users\\wangz\\Downloads\\未翻译词条.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二次检测修复字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "original_language = \"English\"\n",
    "target_language = \"Vietnamese\"\n",
    "def generate_text(index, data):\n",
    "    try:\n",
    "        if str(data['备注']).strip() == 'SPECIAL VALUE' or str(data['备注']).strip() == 'SPECIAL VALUE, INCLUDE UPPERCASE LETTER' or str(data['备注']).strip() == '':\n",
    "            return index, str(data['待翻译(译)']).strip()\n",
    "        if str(data['参考语言(英文)']).strip().lower() != str(data['简体中文(源)']).strip().lower() and str(data['参考语言(英文)']).strip().lower() == str(data['待翻译(译)']).strip().lower():\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": f\"You are an expert in translating {original_language} to {target_language} for ERP systems. Your task is to translate markdown-formatted text from {original_language} to {target_language}. Preserving its formatting without adding extra content.\"},\n",
    "                    {\"role\": \"user\", \"content\": str(data['参考语言(英文)'])}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            return index, completion.choices[0].message.content\n",
    "        if str(data['参考语言(英文)']).strip().lower() == str(data['简体中文(源)']).strip().lower():\n",
    "            return index, str(data['参考语言(英文)']).strip()\n",
    "        else:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": \"Translate English: The received L/G %s is not submitted \\nTo Spanish: El L/G recibido no se ha enviado. \\nPlease fix the translate error, because %s is missing, translate it directly and without adding any extra content.\"},\n",
    "                    {\"role\": \"assistant\", \"content\": \"El L/G recibido %s no se ha enviado.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Translate {original_language}: {str(data['参考语言(英文)'])} \\nTo {target_language}: {str(data['待翻译(译)'])} \\n Please fix the translate error, Because {str(data['备注'])}. translate it directly and without adding any extra content.\"}\n",
    "                ],\n",
    "                temperature=0\n",
    "            )\n",
    "            return index, completion.choices[0].message.content\n",
    "    except:\n",
    "        return index, str(data['待翻译(译)']).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124202/124202 [02:26<00:00, 849.76it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "to_fix = pd.read_excel(r\"D:\\Projects\\ai-translator\\special value\\first_check\\processed_files\\multilangInitData YS全量词条 20241119 Special Value_中_越.xlsx\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "    futures = {executor.submit(generate_text, index, row) for index, row in to_fix.iterrows()}\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        index, output = future.result()\n",
    "\n",
    "        if output is not None:\n",
    "            to_fix.at[index, f'待翻译(译)'] = output\n",
    "\n",
    "to_fix['备注'] = \"\"\n",
    "# 保存最终结果到 Excel 文件\n",
    "to_fix.to_excel(r\"D:\\Projects\\ai-translator\\special value\\first_check\\processed_files\\multilangInitData YS全量词条 20241119 Special Value_中_越_processed.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileCreateError",
     "evalue": "[WinError 2] 系统找不到指定的文件。: 'C:\\\\Users\\\\wangz\\\\AppData\\\\Local\\\\Temp\\\\tmp2dbjpq31'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\xlsxwriter\\workbook.py:360\u001b[0m, in \u001b[0;36mWorkbook.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 360\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\xlsxwriter\\workbook.py:786\u001b[0m, in \u001b[0;36mWorkbook._store_workbook\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    785\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmktime((\u001b[38;5;241m1980\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 786\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 系统找不到指定的文件。: 'C:\\\\Users\\\\wangz\\\\AppData\\\\Local\\\\Temp\\\\tmp2dbjpq31'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileCreateError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(df_list, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 保存合并后的 DataFrame 到新的 Excel 文件\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mProjects\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mai-translator\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msrc\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmultilangInitData20250210空_translated.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\pandas\\core\\generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2407\u001b[0m     df,\n\u001b[0;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[1;32m-> 2417\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\pandas\\io\\formats\\excel.py:962\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m need_save:\n\u001b[1;32m--> 962\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1357\u001b[0m, in \u001b[0;36mExcelWriter.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"synonym for save, to make it more file-like\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:239\u001b[0m, in \u001b[0;36mXlsxWriter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_save\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    Save workbook to disk.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\xlsxwriter\\workbook.py:362\u001b[0m, in \u001b[0;36mWorkbook.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_workbook()\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FileCreateError(e)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LargeZipFile:\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FileSizeError(\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFilesize would require ZIP64 extensions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse workbook.use_zip64().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m     )\n",
      "\u001b[1;31mFileCreateError\u001b[0m: [WinError 2] 系统找不到指定的文件。: 'C:\\\\Users\\\\wangz\\\\AppData\\\\Local\\\\Temp\\\\tmp2dbjpq31'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义要合并的 Excel 文件列表\n",
    "excel_files = [\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_1_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_2_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_3_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_4_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_5_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_6_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_7_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_8_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_9_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_10_translated.xlsx\",\n",
    "    r\"C:\\Users\\wangz\\Downloads\\processed\\part_11_translated.xlsx\",\n",
    "]\n",
    "\n",
    "# 读取并合并所有 Excel 文件\n",
    "df_list = [pd.read_excel(file) for file in excel_files]\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 保存合并后的 DataFrame 到新的 Excel 文件\n",
    "merged_df.to_excel(r\"D:\\Projects\\ai-translator\\src\\multilangInitData20250210空_translated.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文件拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取Excel文件...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda3\\envs\\ai-trans\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel文件总行数: 1030626 行\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_1.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_2.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_3.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_4.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_5.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_6.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_7.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_8.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_9.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_10.xlsx\n",
      "已保存: D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_11.xlsx\n",
      "拆分完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def split_excel(input_file, output_folder, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    将一个Excel文件按指定行数拆分为多个Excel文件，并存储到指定文件夹。\n",
    "\n",
    "    Args:\n",
    "        input_file (str): 输入的Excel文件路径。\n",
    "        output_folder (str): 输出文件夹路径。\n",
    "        chunk_size (int): 每个拆分Excel文件包含的最大行数，默认10万。\n",
    "    \"\"\"\n",
    "    # 检查输出文件夹是否存在，不存在则创建\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # 读取Excel文件（假设默认是Sheet1）\n",
    "    print(\"正在读取Excel文件...\")\n",
    "    excel_data = pd.read_excel(input_file, sheet_name=0)\n",
    "\n",
    "    # 获取总行数\n",
    "    total_rows = excel_data.shape[0]\n",
    "    print(f\"Excel文件总行数: {total_rows} 行\")\n",
    "\n",
    "    # 按chunk_size进行分割\n",
    "    for i in range(0, total_rows, chunk_size):\n",
    "        chunk = excel_data.iloc[i:i + chunk_size]  # 提取数据块\n",
    "        output_file = os.path.join(output_folder, f\"part_{i // chunk_size + 1}.xlsx\")\n",
    "        chunk.to_excel(output_file, index=False, engine='openpyxl')  # 保存为Excel\n",
    "        print(f\"已保存: {output_file}\")\n",
    "    \n",
    "    print(\"拆分完成！\")\n",
    "\n",
    "# 示例用法\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = r\"C:\\Users\\wangz\\Downloads\\multilangInitData20250210空.xlsx\"  # 输入文件路径\n",
    "    output_folder = r\"D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\"  # 输出文件夹路径\n",
    "    split_excel(input_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 友互通翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "繁体中文\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]C:\\Users\\wangz\\AppData\\Local\\Temp\\ipykernel_10712\\2712388074.py:90: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '千人千面按需定製' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  to_fix.at[index, target_column] = output\n",
      "100%|██████████| 41/41 [00:00<00:00, 106.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "印尼语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "匈牙利语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40866.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "葡萄牙语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "泰语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 29969.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "土耳其语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40866.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "越南语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "俄语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 41/41 [00:00<00:00, 40885.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿拉伯语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 41/41 [00:00<00:00, 40856.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "芬兰语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 31.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丹麦语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 27300.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "荷兰语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 27257.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "波兰语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "法语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "德语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40798.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "挪威语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "希伯来语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40866.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "韩语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 30582.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "西班牙语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 32.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "捷克语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "意大利语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:01<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "瑞典语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "希腊语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40885.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "马来语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "斯洛伐克语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40905.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "柬埔寨语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40386.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "罗马尼亚语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40808.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "克罗地亚语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乌兹别克语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 40789.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缅甸语\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import zhconv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "target_columns = [\n",
    "    \"繁体中文\",\n",
    "    \"印尼语\",\n",
    "    \"匈牙利语\",\n",
    "    \"葡萄牙语\",\n",
    "    \"泰语\",\n",
    "    \"土耳其语\",\n",
    "    \"越南语\",\n",
    "    \"俄语\",\n",
    "    \"阿拉伯语\",\n",
    "    \"芬兰语\",\n",
    "    \"丹麦语\",\n",
    "    \"荷兰语\",\n",
    "    \"波兰语\",\n",
    "    \"法语\",\n",
    "    \"德语\",\n",
    "    \"日语\",\n",
    "    \"挪威语\",\n",
    "    \"希伯来语\",\n",
    "    \"韩语\",\n",
    "    \"西班牙语\",\n",
    "    \"捷克语\",\n",
    "    \"意大利语\",\n",
    "    \"瑞典语\",\n",
    "    \"希腊语\",\n",
    "    \"马来语\",\n",
    "    \"斯洛伐克语\",\n",
    "    \"柬埔寨语\",\n",
    "    \"罗马尼亚语\",\n",
    "    \"克罗地亚语\",\n",
    "    \"乌兹别克语\",\n",
    "    \"缅甸语\"\n",
    "]\n",
    "\n",
    "simple_column_name = \"简体中文(源)\"\n",
    "english_column_name = \"English\"\n",
    "trans_column_name = \"繁体中文\"\n",
    "\n",
    "for target_column in target_columns:\n",
    "    print(target_column)\n",
    "    dictionary = {}\n",
    "\n",
    "    def generate_text(index, data):\n",
    "        if not pd.isnull(data[target_column]):\n",
    "            dictionary[str(data[english_column_name])] = data[target_column]\n",
    "            return index, data[target_column]\n",
    "        if str(data[english_column_name]) in dictionary.keys():\n",
    "            return index, dictionary[str(data[english_column_name])]\n",
    "        if target_column == trans_column_name:\n",
    "            return index, zhconv.convert(str(data[simple_column_name]), 'zh-tw')\n",
    "        completion = client.chat.completions.create(\n",
    "            model='gpt-4o',\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": f\"Translate the following sentence from English to {simple_column_name}: {str(data[english_column_name])}, please directly translate it and do not output any extra content\"},\n",
    "                {\"role\": \"assistant\", \"content\": str(data[simple_column_name])},\n",
    "                {\"role\": \"user\", \"content\": f\"Translate the following sentence from English to {trans_column_name}: {str(data[english_column_name])}, please directly translate it and do not output any extra content\"},\n",
    "                {\"role\": \"assistant\", \"content\": str(data[trans_column_name])},\n",
    "                {\"role\": \"user\", \"content\": f\"Translate the following sentence from English to {target_column}: {str(data[english_column_name])}, please directly translate it and do not output any extra content\"}\n",
    "            ],\n",
    "            # messages=[\n",
    "            #     {\"role\": \"user\", \"content\": f\"Translate the following sentence from Chinese to {english_column_name}: {str(data[simple_column_name])}, please directly translate it and do not output any extra content\"},\n",
    "            #     {\"role\": \"assistant\", \"content\": str(data[english_column_name])},\n",
    "            #     {\"role\": \"user\", \"content\": f\"Translate the following sentence from Chinese to {trans_column_name}: {str(data[simple_column_name])}, please directly translate it and do not output any extra content\"},\n",
    "            #     {\"role\": \"assistant\", \"content\": str(data[trans_column_name])},\n",
    "            #     {\"role\": \"user\", \"content\": f\"Translate the following sentence from Chinese to {target_column}: {str(data[simple_column_name])}, please directly translate it and do not output any extra content\"}\n",
    "            # ],\n",
    "            temperature=0\n",
    "        )\n",
    "        dictionary[str(data[english_column_name])] = completion.choices[0].message.content\n",
    "        return index, completion.choices[0].message.content\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "    import pandas as pd\n",
    "    to_fix = pd.read_excel(r\"C:\\Users\\wangz\\Downloads\\20250227-友空间-iOS.xlsx\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        futures = {executor.submit(generate_text, index, row) for index, row in to_fix.iterrows()}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            index, output = future.result()\n",
    "\n",
    "            if output is not None:\n",
    "                to_fix.at[index, target_column] = output\n",
    "\n",
    "    # 保存最终结果到 Excel 文件\n",
    "    to_fix.to_excel(r\"C:\\Users\\wangz\\Downloads\\20250227-友空间-iOS.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(files=['C:\\\\Users\\\\wangz\\\\Downloads\\\\Megatron-LM： Training Multi-Billion Parameter Language Models Using.pdf'], debug=False, pages=None, vfont='', vchar='', lang_in='en', lang_out='zh', service='openai', output='', thread=4, interactive=False, share=False, flask=False, celery=False, authorized=None, prompt=None, compatible=False, onnx=None, serverport=None, dir=False, config=None, yadt=False)\n",
      "Downloading SourceHanSerifCN-Regular.ttf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      " 13%|█▎        | 2/15 [00:05<00:36,  2.78s/it]\n",
      " 20%|██        | 3/15 [00:19<01:31,  7.64s/it]\n",
      " 27%|██▋       | 4/15 [00:26<01:21,  7.39s/it]\n",
      " 33%|███▎      | 5/15 [00:34<01:13,  7.36s/it]\n",
      " 40%|████      | 6/15 [00:41<01:05,  7.24s/it]\n",
      " 47%|████▋     | 7/15 [00:49<01:01,  7.69s/it]\n",
      " 53%|█████▎    | 8/15 [00:55<00:48,  6.98s/it]\n",
      " 60%|██████    | 9/15 [01:02<00:42,  7.06s/it]\n",
      " 67%|██████▋   | 10/15 [01:15<00:44,  8.85s/it]\n",
      " 73%|███████▎  | 11/15 [01:24<00:35,  8.79s/it]\n",
      " 80%|████████  | 12/15 [01:31<00:25,  8.43s/it]\n",
      " 87%|████████▋ | 13/15 [01:39<00:16,  8.22s/it]\n",
      " 93%|█████████▎| 14/15 [01:47<00:08,  8.08s/it]\n",
      "100%|██████████| 15/15 [01:54<00:00,  7.91s/it]\n",
      "100%|██████████| 15/15 [02:02<00:00,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(files=['C:\\\\Users\\\\wangz\\\\Downloads\\\\Efficient Large-Scale Language Model Training on GPU Clusters.pdf'], debug=False, pages=None, vfont='', vchar='', lang_in='en', lang_out='zh', service='openai', output='', thread=4, interactive=False, share=False, flask=False, celery=False, authorized=None, prompt=None, compatible=False, onnx=None, serverport=None, dir=False, config=None, yadt=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      " 15%|█▌        | 2/13 [00:11<01:03,  5.80s/it]\n",
      " 23%|██▎       | 3/13 [00:19<01:08,  6.84s/it]\n",
      " 31%|███       | 4/13 [00:24<00:54,  6.11s/it]\n",
      " 38%|███▊      | 5/13 [00:33<00:56,  7.10s/it]\n",
      " 46%|████▌     | 6/13 [00:41<00:50,  7.18s/it]\n",
      " 54%|█████▍    | 7/13 [00:49<00:44,  7.48s/it]\n",
      " 62%|██████▏   | 8/13 [00:58<00:39,  7.92s/it]\n",
      " 69%|██████▉   | 9/13 [01:04<00:30,  7.54s/it]\n",
      " 77%|███████▋  | 10/13 [01:09<00:19,  6.58s/it]\n",
      " 85%|████████▍ | 11/13 [01:18<00:14,  7.38s/it]\n",
      " 92%|█████████▏| 12/13 [01:36<00:10, 10.72s/it]\n",
      "100%|██████████| 13/13 [01:48<00:00, 11.17s/it]\n",
      "100%|██████████| 13/13 [02:07<00:00,  9.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(files=['C:\\\\Users\\\\wangz\\\\Downloads\\\\Reducing Activation Recomputation.pdf'], debug=False, pages=None, vfont='', vchar='', lang_in='en', lang_out='zh', service='openai', output='', thread=4, interactive=False, share=False, flask=False, celery=False, authorized=None, prompt=None, compatible=False, onnx=None, serverport=None, dir=False, config=None, yadt=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]\n",
      " 12%|█▏        | 2/17 [00:05<00:42,  2.84s/it]\n",
      " 18%|█▊        | 3/17 [00:09<00:43,  3.13s/it]\n",
      " 24%|██▎       | 4/17 [00:17<01:06,  5.14s/it]\n",
      " 29%|██▉       | 5/17 [00:28<01:24,  7.03s/it]\n",
      " 35%|███▌      | 6/17 [00:31<01:03,  5.79s/it]\n",
      " 41%|████      | 7/17 [00:38<01:02,  6.21s/it]\n",
      " 47%|████▋     | 8/17 [00:42<00:49,  5.55s/it]\n",
      " 53%|█████▎    | 9/17 [00:48<00:45,  5.66s/it]\n",
      " 59%|█████▉    | 10/17 [00:54<00:40,  5.78s/it]\n",
      " 65%|██████▍   | 11/17 [00:59<00:31,  5.31s/it]\n",
      " 71%|███████   | 12/17 [01:03<00:25,  5.03s/it]\n",
      " 76%|███████▋  | 13/17 [01:07<00:18,  4.71s/it]\n",
      " 82%|████████▏ | 14/17 [01:14<00:16,  5.38s/it]\n",
      " 88%|████████▊ | 15/17 [01:24<00:13,  6.91s/it]\n",
      " 94%|█████████▍| 16/17 [01:31<00:06,  6.73s/it]\n",
      "100%|██████████| 17/17 [01:36<00:00,  6.40s/it]\n",
      "100%|██████████| 17/17 [01:39<00:00,  5.85s/it]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "!pdf2zh \"C:\\Users\\wangz\\Downloads\\Megatron-LM： Training Multi-Billion Parameter Language Models Using.pdf\" -li en -lo zh -s openai\n",
    "!pdf2zh \"C:\\Users\\wangz\\Downloads\\Efficient Large-Scale Language Model Training on GPU Clusters.pdf\" -li en -lo zh -s openai\n",
    "!pdf2zh \"C:\\Users\\wangz\\Downloads\\Reducing Activation Recomputation.pdf\" -li en -lo zh -s openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'matahari\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(base_url=\"https://generativelanguage.googleapis.com/v1beta/\", api_key=\"\")\n",
    "target_column = \"印尼语\"\n",
    "\n",
    "def generate_text(index, data):\n",
    "    if not pd.isnull(data[target_column]):\n",
    "        return index, data[target_column]\n",
    "    completion = client.chat.completions.create(\n",
    "        model='gemini-1.5-flash',\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Translate English to Chinese: {str(data['English(译)'])}, please directly translate it and do not output any extra content\"},\n",
    "            {\"role\": \"assistant\", \"content\": str(data['简体中文(源)'])},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate English to Traditional Chinese: {str(data['English(译)'])}, please directly translate it and do not output any extra content\"},\n",
    "            {\"role\": \"assistant\", \"content\": str(data['繁体中文（译）'])},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate English to {target_column}: {str(data['English(译)'])}, please directly translate it and do not output any extra content\"}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return index, completion.choices[0].message.content\n",
    "\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "to_fix = pd.read_excel(r\"D:\\Projects\\ai-translator\\src\\友互通\\友互通-全.xlsx\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "    futures = {executor.submit(generate_text, index, row) for index, row in to_fix.iterrows()}\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        index, output = future.result()\n",
    "\n",
    "        if output is not None:\n",
    "            to_fix.at[index, target_column] = output\n",
    "\n",
    "# 保存最终结果到 Excel 文件\n",
    "to_fix.to_excel(r\"D:\\Projects\\ai-translator\\src\\友互通\\友互通-全.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 翻译123种语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初翻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14640/14640 [02:03<00:00, 118.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "\n",
    "# Load environment variables and set OpenAI API key\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "data = pd.read_excel(r\"C:\\Users\\wangz\\Downloads\\20241203 123种语种翻译数据.xlsx\")\n",
    "\n",
    "# Define the columns and rows to process\n",
    "columns = data.columns.to_list()[4:]  # Exclude the first 4 columns\n",
    "rows = data.index[2:]  # Start from the third row\n",
    "\n",
    "# Prepare the list of tasks for translation\n",
    "tasks = []\n",
    "for column in columns:\n",
    "    for row_index in rows:\n",
    "        text_to_translate = data.at[row_index, 'zh_CN']\n",
    "        tasks.append((row_index, column, text_to_translate))\n",
    "\n",
    "# Initialize a lock for thread-safe DataFrame operations\n",
    "data_lock = threading.Lock()\n",
    "max_workers = 2000  # Adjust the number of threads as needed\n",
    "\n",
    "# Define the function to translate a single cell\n",
    "def translate_cell(task):\n",
    "    row_index, column, text_to_translate = task\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Translate '简体中文' to {column}, translate it directly and without adding any extra content.\"},\n",
    "        {\"role\": \"assistant\", \"content\": str(data[column][1])},\n",
    "        {\"role\": \"user\", \"content\": f\"Translate '{text_to_translate}' to {column}, translate it directly and without adding any extra content.\"}\n",
    "    ]\n",
    "    try:\n",
    "        completion =  client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0\n",
    "        )\n",
    "        translated_text = completion.choices[0].message.content\n",
    "        # Write the translated text back to the DataFrame in a thread-safe manner\n",
    "        with data_lock:\n",
    "            data.at[row_index, column] = translated_text\n",
    "        return (row_index, column, translated_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating row {row_index}, column {column}: {e}\")\n",
    "        return (row_index, column, None)\n",
    "\n",
    "# Execute the translation tasks using a ThreadPoolExecutor and display a progress bar\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(translate_cell, task) for task in tasks]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        pass  # The results are handled within the translate_cell function\n",
    "\n",
    "# Save the translated DataFrame to a new Excel file\n",
    "data.to_excel(\"translated_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:03<00:00, 32.88it/s] \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "\n",
    "# Load environment variables and set OpenAI API key\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "data = pd.read_excel(r\"C:\\Users\\wangz\\Documents\\WeChat Files\\wxid_eet1drkwse4k22\\FileStorage\\File\\2024-12\\20241203 123种语种翻译数据-GPT 确认.xlsx\")\n",
    "\n",
    "# Define the columns and rows to process\n",
    "columns = data.columns.to_list()[4:]  # Exclude the first 4 columns\n",
    "rows = data.index[2:]  # Start from the third row\n",
    "\n",
    "# Prepare the list of tasks for translation\n",
    "tasks = []\n",
    "for column in columns:\n",
    "    for row_index in rows:\n",
    "        text_to_translate = data.at[row_index, 'zh_CN']\n",
    "        if text_to_translate == '挪威语':\n",
    "            tasks.append((row_index, column, text_to_translate))\n",
    "            break  # Only translate the first occurrence\n",
    "\n",
    "# Initialize a lock for thread-safe DataFrame operations\n",
    "data_lock = threading.Lock()\n",
    "max_workers = 2000  # Adjust the number of threads as needed\n",
    "\n",
    "# Define the function to translate a single cell\n",
    "def translate_cell(task):\n",
    "    row_index, column, text_to_translate = task\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"Translate '简体中文' to {column}, translate it directly and without adding any extra content.\"},\n",
    "        {\"role\": \"assistant\", \"content\": str(data[column][1])},\n",
    "        {\"role\": \"user\", \"content\": f\"Translate '{text_to_translate}' to {column}, translate it directly and without adding any extra content.\"}\n",
    "    ]\n",
    "    try:\n",
    "        completion =  client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            temperature=0\n",
    "        )\n",
    "        translated_text = completion.choices[0].message.content\n",
    "        # Write the translated text back to the DataFrame in a thread-safe manner\n",
    "        with data_lock:\n",
    "            data.at[row_index, column] = translated_text\n",
    "        return (row_index, column, translated_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating row {row_index}, column {column}: {e}\")\n",
    "        return (row_index, column, None)\n",
    "\n",
    "# Execute the translation tasks using a ThreadPoolExecutor and display a progress bar\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(translate_cell, task) for task in tasks]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        pass  # The results are handled within the translate_cell function\n",
    "\n",
    "# Save the translated DataFrame to a new Excel file\n",
    "data.to_excel(\"translated_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精翻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14640/14640 [00:01<00:00, 14606.36it/s] \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "\n",
    "# Load environment variables and set OpenAI API key\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "data = pd.read_excel(r\"D:\\Projects\\ai-translator\\src\\translated_data.xlsx\")\n",
    "\n",
    "# Define the columns and rows to process\n",
    "columns = data.columns.to_list()[4:]  # Exclude the first 4 columns\n",
    "rows = data.index[2:]  # Start from the third row\n",
    "\n",
    "# Prepare the list of tasks for translation\n",
    "tasks = []\n",
    "for column in columns:\n",
    "    for row_index in rows:\n",
    "        text_to_translate = data.at[row_index, 'zh_CN']\n",
    "        tasks.append((row_index, column, text_to_translate))\n",
    "\n",
    "# Initialize a lock for thread-safe DataFrame operations\n",
    "data_lock = threading.Lock()\n",
    "max_workers = 2000  # Adjust the number of threads as needed\n",
    "\n",
    "# Define the function to translate a single cell\n",
    "def translate_cell(task):\n",
    "    row_index, column, text_to_translate = task\n",
    "    if text_to_translate.strip() == data.at[row_index, column].strip():\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": f\"Translate '简体中文' to {column}, translate it directly and without adding any extra content.\"},\n",
    "            {\"role\": \"assistant\", \"content\": str(data[column][1])},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate '{text_to_translate}' to {column}, translate it directly and without adding any extra content.\"}\n",
    "        ]\n",
    "        try:\n",
    "            completion =  client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=messages,\n",
    "                temperature=0\n",
    "            )\n",
    "            translated_text = completion.choices[0].message.content\n",
    "            # Write the translated text back to the DataFrame in a thread-safe manner\n",
    "            with data_lock:\n",
    "                data.at[row_index, column] = translated_text\n",
    "            return (row_index, column, translated_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error translating row {row_index}, column {column}: {e}\")\n",
    "            return (row_index, column, None)\n",
    "    else:\n",
    "        return (row_index, column, data.at[row_index, column])\n",
    "\n",
    "# Execute the translation tasks using a ThreadPoolExecutor and display a progress bar\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(translate_cell, task) for task in tasks]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        pass  # The results are handled within the translate_cell function\n",
    "\n",
    "# Save the translated DataFrame to a new Excel file\n",
    "data.to_excel(\"translated_data_1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计文件夹下的文件数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件总数为: 5001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files(folder_path):\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        total_files += len(files)  # 统计当前目录的文件数量\n",
    "    return total_files\n",
    "\n",
    "# 输入文件夹路径\n",
    "folder_path = r\"C:\\Users\\wangz\\Documents\\WeChat Files\\wxid_eet1drkwse4k22\\FileStorage\\File\\2024-12\\高级版2312帮助文档（English）\\高级版2312帮助文档（English）\"\n",
    "file_count = count_files(folder_path)\n",
    "print(f\"文件总数为: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 翻译越南语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import zhconv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "target_columns = [\n",
    "    \"目标语言\"\n",
    "]\n",
    "\n",
    "for target_column in target_columns:\n",
    "    dictionary = {}\n",
    "\n",
    "    def generate_text(index, data):\n",
    "        if not pd.isnull(data[target_column]):\n",
    "            dictionary[str(data['English(译)'])] = data[target_column]\n",
    "            return index, data[target_column]\n",
    "        if str(data['English(译)']) in dictionary.keys():\n",
    "            return index, dictionary[str(data['English(译)'])]\n",
    "        if target_column == \"繁体中文（译）\":\n",
    "            return index, zhconv.convert(str(data['简体中文(源)']), 'zh-tw')\n",
    "        completion = client.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": f\"Translate English to Chinese: {str(data['English(译)'])}, please directly translate it and do not output any extra content\"},\n",
    "                {\"role\": \"assistant\", \"content\": str(data['简体中文(源)'])},\n",
    "                {\"role\": \"user\", \"content\": f\"Translate English to Traditional Chinese: {str(data['English(译)'])}, please directly translate it and do not output any extra content\"},\n",
    "                {\"role\": \"assistant\", \"content\": str(data[\"繁体中文（译）\"])},\n",
    "                {\"role\": \"user\", \"content\": f\"Translate English to {target_column}: {str(data['English(译)'])}, please directly translate it and do not output any extra content\"}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        dictionary[str(data['English(译)'])] = completion.choices[0].message.content\n",
    "        return index, completion.choices[0].message.content\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "    import pandas as pd\n",
    "    to_fix = pd.read_excel(r\"C:\\Users\\wangz\\Downloads\\前端词条补充翻译-20241227\\TINPERNEXTPRO-FE_en_US20241226203251.xlsx\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        futures = {executor.submit(generate_text, index, row) for index, row in to_fix.iterrows()}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            index, output = future.result()\n",
    "\n",
    "            if output is not None:\n",
    "                to_fix.at[index, target_column] = output\n",
    "\n",
    "    # 保存最终结果到 Excel 文件\n",
    "    to_fix.to_excel(r\"C:\\Users\\wangz\\Downloads\\前端词条补充翻译-20241227\\TINPERNEXTPRO-FE_en_US20241226203251.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清理后的文件已保存为: Cleaned_Chinese_Column.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 Excel 文件\n",
    "file_path = r\"C:\\Users\\wangz\\Desktop\\新建 XLSX 工作表.xlsx\"  # 替换为你的文件路径\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 删除 Chinese 列中的重复项，仅保留最后一个\n",
    "df_cleaned = df.drop_duplicates(subset=\"Chinese\", keep=\"last\")\n",
    "\n",
    "# 保存清理后的数据到新 Excel 文件\n",
    "output_path = \"Cleaned_Chinese_Column.xlsx\"\n",
    "df_cleaned.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"清理后的文件已保存为: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI language model created by OpenAI, designed to assist with a wide range of questions and tasks by providing information, answering queries, and engaging in conversation. How can I help you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Who are you?\"\n",
    "    }],\n",
    "    temperature=0,\n",
    "    logprobs=True,\n",
    "    top_p=1\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "logprobs = [token.logprob for token in completion.choices[0].logprobs.content]\n",
    "probs = np.exp(logprobs)\n",
    "geo_mean_confidence = np.prod(probs) ** (1 / len(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9011096809216835"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(geo_mean_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF2DOCX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\03-YonBIP旗舰版专业开发-开发介绍-数字化工作台介绍（含开发者中心和YMS介绍）.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 03-YonBIP旗舰版专业开发-开发介绍-数字化工作台介绍（含开发者中心和YMS介绍）.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/45) Page 1\n",
      "[INFO] (2/45) Page 2\n",
      "[INFO] (3/45) Page 3\n",
      "[INFO] (4/45) Page 4\n",
      "[INFO] (5/45) Page 5\n",
      "[INFO] (6/45) Page 6\n",
      "[INFO] (7/45) Page 7\n",
      "[INFO] (8/45) Page 8\n",
      "[INFO] (9/45) Page 9\n",
      "[INFO] (10/45) Page 10\n",
      "[INFO] (11/45) Page 11\n",
      "[INFO] (12/45) Page 12\n",
      "[INFO] (13/45) Page 13\n",
      "[INFO] (14/45) Page 14\n",
      "[INFO] (15/45) Page 15\n",
      "[INFO] (16/45) Page 16\n",
      "[INFO] (17/45) Page 17\n",
      "[INFO] (18/45) Page 18\n",
      "[INFO] (19/45) Page 19\n",
      "[INFO] (20/45) Page 20\n",
      "[INFO] (21/45) Page 21\n",
      "[INFO] (22/45) Page 22\n",
      "[INFO] (23/45) Page 23\n",
      "[INFO] (24/45) Page 24\n",
      "[INFO] (25/45) Page 25\n",
      "[INFO] (26/45) Page 26\n",
      "[INFO] (27/45) Page 27\n",
      "[INFO] (28/45) Page 28\n",
      "[INFO] (29/45) Page 29\n",
      "[INFO] (30/45) Page 30\n",
      "[INFO] (31/45) Page 31\n",
      "[INFO] (32/45) Page 32\n",
      "[INFO] (33/45) Page 33\n",
      "[INFO] (34/45) Page 34\n",
      "[INFO] (35/45) Page 35\n",
      "[INFO] (36/45) Page 36\n",
      "[INFO] (37/45) Page 37\n",
      "[INFO] (38/45) Page 38\n",
      "[INFO] (39/45) Page 39\n",
      "[INFO] (40/45) Page 40\n",
      "[INFO] (41/45) Page 41\n",
      "[INFO] (42/45) Page 42\n",
      "[INFO] (43/45) Page 43\n",
      "[INFO] (44/45) Page 44\n",
      "[INFO] (45/45) Page 45\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/45) Page 1\n",
      "[INFO] (2/45) Page 2\n",
      "[INFO] (3/45) Page 3\n",
      "[INFO] (4/45) Page 4\n",
      "[INFO] (5/45) Page 5\n",
      "[INFO] (6/45) Page 6\n",
      "[INFO] (7/45) Page 7\n",
      "[INFO] (8/45) Page 8\n",
      "[INFO] (9/45) Page 9\n",
      "[INFO] (10/45) Page 10\n",
      "[INFO] (11/45) Page 11\n",
      "[INFO] (12/45) Page 12\n",
      "[INFO] (13/45) Page 13\n",
      "[INFO] (14/45) Page 14\n",
      "[INFO] (15/45) Page 15\n",
      "[INFO] (16/45) Page 16\n",
      "[INFO] (17/45) Page 17\n",
      "[INFO] (18/45) Page 18\n",
      "[INFO] (19/45) Page 19\n",
      "[INFO] (20/45) Page 20\n",
      "[INFO] (21/45) Page 21\n",
      "[INFO] (22/45) Page 22\n",
      "[INFO] (23/45) Page 23\n",
      "[INFO] (24/45) Page 24\n",
      "[INFO] (25/45) Page 25\n",
      "[INFO] (26/45) Page 26\n",
      "[INFO] (27/45) Page 27\n",
      "[INFO] (28/45) Page 28\n",
      "[INFO] (29/45) Page 29\n",
      "[INFO] (30/45) Page 30\n",
      "[INFO] (31/45) Page 31\n",
      "[INFO] (32/45) Page 32\n",
      "[INFO] (33/45) Page 33\n",
      "[INFO] (34/45) Page 34\n",
      "[INFO] (35/45) Page 35\n",
      "[INFO] (36/45) Page 36\n",
      "[INFO] (37/45) Page 37\n",
      "[INFO] (38/45) Page 38\n",
      "[INFO] (39/45) Page 39\n",
      "[INFO] (40/45) Page 40\n",
      "[INFO] (41/45) Page 41\n",
      "[INFO] (42/45) Page 42\n",
      "[INFO] (43/45) Page 43\n",
      "[INFO] (44/45) Page 44\n",
      "[INFO] (45/45) Page 45\n",
      "[INFO] Terminated in 294.07s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\07-YonBIP旗舰版专业开发-开发介绍-客开介绍.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 03-YonBIP旗舰版专业开发-开发介绍-数字化工作台介绍（含开发者中心和YMS介绍）.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\03-YonBIP旗舰版专业开发-开发介绍-数字化工作台介绍（含开发者中心和YMS介绍）.docx\n",
      "Converting 07-YonBIP旗舰版专业开发-开发介绍-客开介绍.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/13) Page 1\n",
      "[INFO] (2/13) Page 2\n",
      "[INFO] (3/13) Page 3\n",
      "[INFO] (4/13) Page 4\n",
      "[INFO] (5/13) Page 5\n",
      "[INFO] (6/13) Page 6\n",
      "[INFO] (7/13) Page 7\n",
      "[INFO] (8/13) Page 8\n",
      "[INFO] (9/13) Page 9\n",
      "[INFO] (10/13) Page 10\n",
      "[INFO] (11/13) Page 11\n",
      "[INFO] (12/13) Page 12\n",
      "[INFO] (13/13) Page 13\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/13) Page 1\n",
      "[INFO] (2/13) Page 2\n",
      "[INFO] (3/13) Page 3\n",
      "[INFO] (4/13) Page 4\n",
      "[INFO] (5/13) Page 5\n",
      "[INFO] (6/13) Page 6\n",
      "[INFO] (7/13) Page 7\n",
      "[INFO] (8/13) Page 8\n",
      "[INFO] (9/13) Page 9\n",
      "[INFO] (10/13) Page 10\n",
      "[INFO] (11/13) Page 11\n",
      "[INFO] (12/13) Page 12\n",
      "[INFO] (13/13) Page 13\n",
      "[INFO] Terminated in 24.93s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\12-YonBIP旗舰版专业开发-开发指南-新功能开发-前端UI组件开发.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 07-YonBIP旗舰版专业开发-开发介绍-客开介绍.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\07-YonBIP旗舰版专业开发-开发介绍-客开介绍.docx\n",
      "Converting 12-YonBIP旗舰版专业开发-开发指南-新功能开发-前端UI组件开发.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/30) Page 1\n",
      "[INFO] (2/30) Page 2\n",
      "[INFO] (3/30) Page 3\n",
      "[INFO] (4/30) Page 4\n",
      "[INFO] (5/30) Page 5\n",
      "[INFO] (6/30) Page 6\n",
      "[INFO] (7/30) Page 7\n",
      "[INFO] (8/30) Page 8\n",
      "[INFO] (9/30) Page 9\n",
      "[INFO] (10/30) Page 10\n",
      "[INFO] (11/30) Page 11\n",
      "[INFO] (12/30) Page 12\n",
      "[INFO] (13/30) Page 13\n",
      "[INFO] (14/30) Page 14\n",
      "[INFO] (15/30) Page 15\n",
      "[INFO] (16/30) Page 16\n",
      "[INFO] (17/30) Page 17\n",
      "[INFO] (18/30) Page 18\n",
      "[INFO] (19/30) Page 19\n",
      "[INFO] (20/30) Page 20\n",
      "[INFO] (21/30) Page 21\n",
      "[INFO] (22/30) Page 22\n",
      "[INFO] (23/30) Page 23\n",
      "[INFO] (24/30) Page 24\n",
      "[INFO] (25/30) Page 25\n",
      "[INFO] (26/30) Page 26\n",
      "[INFO] (27/30) Page 27\n",
      "[INFO] (28/30) Page 28\n",
      "[INFO] (29/30) Page 29\n",
      "[INFO] (30/30) Page 30\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/30) Page 1\n",
      "[INFO] (2/30) Page 2\n",
      "[INFO] (3/30) Page 3\n",
      "[INFO] (4/30) Page 4\n",
      "[INFO] (5/30) Page 5\n",
      "[INFO] (6/30) Page 6\n",
      "[INFO] (7/30) Page 7\n",
      "[INFO] (8/30) Page 8\n",
      "[INFO] (9/30) Page 9\n",
      "[INFO] (10/30) Page 10\n",
      "[INFO] (11/30) Page 11\n",
      "[INFO] (12/30) Page 12\n",
      "[INFO] (13/30) Page 13\n",
      "[INFO] (14/30) Page 14\n",
      "[INFO] (15/30) Page 15\n",
      "[INFO] (16/30) Page 16\n",
      "[INFO] (17/30) Page 17\n",
      "[INFO] (18/30) Page 18\n",
      "[INFO] (19/30) Page 19\n",
      "[INFO] (20/30) Page 20\n",
      "[INFO] (21/30) Page 21\n",
      "[INFO] (22/30) Page 22\n",
      "[INFO] (23/30) Page 23\n",
      "[INFO] (24/30) Page 24\n",
      "[INFO] (25/30) Page 25\n",
      "[INFO] (26/30) Page 26\n",
      "[INFO] (27/30) Page 27\n",
      "[INFO] (28/30) Page 28\n",
      "[INFO] (29/30) Page 29\n",
      "[INFO] (30/30) Page 30\n",
      "[INFO] Terminated in 3.82s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\13-YonBIP旗舰版专业开发-开发指南-新功能开发-前端样式开发.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 12-YonBIP旗舰版专业开发-开发指南-新功能开发-前端UI组件开发.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\12-YonBIP旗舰版专业开发-开发指南-新功能开发-前端UI组件开发.docx\n",
      "Converting 13-YonBIP旗舰版专业开发-开发指南-新功能开发-前端样式开发.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/25) Page 1\n",
      "[INFO] (2/25) Page 2\n",
      "[INFO] (3/25) Page 3\n",
      "[INFO] (4/25) Page 4\n",
      "[INFO] (5/25) Page 5\n",
      "[INFO] (6/25) Page 6\n",
      "[INFO] (7/25) Page 7\n",
      "[INFO] (8/25) Page 8\n",
      "[INFO] (9/25) Page 9\n",
      "[INFO] (10/25) Page 10\n",
      "[INFO] (11/25) Page 11\n",
      "[INFO] (12/25) Page 12\n",
      "[INFO] (13/25) Page 13\n",
      "[INFO] (14/25) Page 14\n",
      "[INFO] (15/25) Page 15\n",
      "[INFO] (16/25) Page 16\n",
      "[INFO] (17/25) Page 17\n",
      "[INFO] (18/25) Page 18\n",
      "[INFO] (19/25) Page 19\n",
      "[INFO] (20/25) Page 20\n",
      "[INFO] (21/25) Page 21\n",
      "[INFO] (22/25) Page 22\n",
      "[INFO] (23/25) Page 23\n",
      "[INFO] (24/25) Page 24\n",
      "[INFO] (25/25) Page 25\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/25) Page 1\n",
      "[INFO] (2/25) Page 2\n",
      "[INFO] (3/25) Page 3\n",
      "[INFO] (4/25) Page 4\n",
      "[INFO] (5/25) Page 5\n",
      "[INFO] (6/25) Page 6\n",
      "[INFO] (7/25) Page 7\n",
      "[INFO] (8/25) Page 8\n",
      "[INFO] (9/25) Page 9\n",
      "[INFO] (10/25) Page 10\n",
      "[INFO] (11/25) Page 11\n",
      "[INFO] (12/25) Page 12\n",
      "[INFO] (13/25) Page 13\n",
      "[INFO] (14/25) Page 14\n",
      "[INFO] (15/25) Page 15\n",
      "[INFO] (16/25) Page 16\n",
      "[INFO] (17/25) Page 17\n",
      "[INFO] (18/25) Page 18\n",
      "[INFO] (19/25) Page 19\n",
      "[INFO] (20/25) Page 20\n",
      "[INFO] (21/25) Page 21\n",
      "[INFO] (22/25) Page 22\n",
      "[INFO] (23/25) Page 23\n",
      "[INFO] (24/25) Page 24\n",
      "[INFO] (25/25) Page 25\n",
      "[INFO] Terminated in 3.49s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\14-YonBIP旗舰版专业开发-开发指南-新功能开发-前端查询方案开发.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 13-YonBIP旗舰版专业开发-开发指南-新功能开发-前端样式开发.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\13-YonBIP旗舰版专业开发-开发指南-新功能开发-前端样式开发.docx\n",
      "Converting 14-YonBIP旗舰版专业开发-开发指南-新功能开发-前端查询方案开发.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/26) Page 1\n",
      "[INFO] (2/26) Page 2\n",
      "[INFO] (3/26) Page 3\n",
      "[INFO] (4/26) Page 4\n",
      "[INFO] (5/26) Page 5\n",
      "[INFO] (6/26) Page 6\n",
      "[INFO] (7/26) Page 7\n",
      "[INFO] (8/26) Page 8\n",
      "[INFO] (9/26) Page 9\n",
      "[INFO] (10/26) Page 10\n",
      "[INFO] (11/26) Page 11\n",
      "[INFO] (12/26) Page 12\n",
      "[INFO] (13/26) Page 13\n",
      "[INFO] (14/26) Page 14\n",
      "[INFO] (15/26) Page 15\n",
      "[INFO] (16/26) Page 16\n",
      "[INFO] (17/26) Page 17\n",
      "[INFO] (18/26) Page 18\n",
      "[INFO] (19/26) Page 19\n",
      "[INFO] (20/26) Page 20\n",
      "[INFO] (21/26) Page 21\n",
      "[INFO] (22/26) Page 22\n",
      "[INFO] (23/26) Page 23\n",
      "[INFO] (24/26) Page 24\n",
      "[INFO] (25/26) Page 25\n",
      "[INFO] (26/26) Page 26\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/26) Page 1\n",
      "[INFO] (2/26) Page 2\n",
      "[INFO] (3/26) Page 3\n",
      "[INFO] (4/26) Page 4\n",
      "[INFO] (5/26) Page 5\n",
      "[INFO] (6/26) Page 6\n",
      "[INFO] (7/26) Page 7\n",
      "[INFO] (8/26) Page 8\n",
      "[INFO] (9/26) Page 9\n",
      "[INFO] (10/26) Page 10\n",
      "[INFO] (11/26) Page 11\n",
      "[INFO] (12/26) Page 12\n",
      "[INFO] (13/26) Page 13\n",
      "[INFO] (14/26) Page 14\n",
      "[INFO] (15/26) Page 15\n",
      "[INFO] (16/26) Page 16\n",
      "[INFO] (17/26) Page 17\n",
      "[INFO] (18/26) Page 18\n",
      "[INFO] (19/26) Page 19\n",
      "[INFO] (20/26) Page 20\n",
      "[INFO] (21/26) Page 21\n",
      "[INFO] (22/26) Page 22\n",
      "[INFO] (23/26) Page 23\n",
      "[INFO] (24/26) Page 24\n",
      "[INFO] (25/26) Page 25\n",
      "[INFO] (26/26) Page 26\n",
      "[INFO] Terminated in 3.52s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\16-YonBIP旗舰版专业开发-开发指南-成果迁移-开发成果迁移（R6）.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 14-YonBIP旗舰版专业开发-开发指南-新功能开发-前端查询方案开发.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\14-YonBIP旗舰版专业开发-开发指南-新功能开发-前端查询方案开发.docx\n",
      "Converting 16-YonBIP旗舰版专业开发-开发指南-成果迁移-开发成果迁移（R6）.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/29) Page 1\n",
      "[INFO] (2/29) Page 2\n",
      "[INFO] (3/29) Page 3\n",
      "[INFO] (4/29) Page 4\n",
      "[INFO] (5/29) Page 5\n",
      "[INFO] (6/29) Page 6\n",
      "[INFO] (7/29) Page 7\n",
      "[INFO] (8/29) Page 8\n",
      "[INFO] (9/29) Page 9\n",
      "[INFO] (10/29) Page 10\n",
      "[INFO] (11/29) Page 11\n",
      "[INFO] (12/29) Page 12\n",
      "[INFO] (13/29) Page 13\n",
      "[INFO] (14/29) Page 14\n",
      "[INFO] (15/29) Page 15\n",
      "[INFO] (16/29) Page 16\n",
      "[INFO] (17/29) Page 17\n",
      "[INFO] (18/29) Page 18\n",
      "[INFO] (19/29) Page 19\n",
      "[INFO] (20/29) Page 20\n",
      "[INFO] (21/29) Page 21\n",
      "[INFO] (22/29) Page 22\n",
      "[INFO] (23/29) Page 23\n",
      "[INFO] (24/29) Page 24\n",
      "[INFO] (25/29) Page 25\n",
      "[INFO] (26/29) Page 26\n",
      "[INFO] (27/29) Page 27\n",
      "[INFO] (28/29) Page 28\n",
      "[INFO] (29/29) Page 29\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/29) Page 1\n",
      "[INFO] (2/29) Page 2\n",
      "[INFO] (3/29) Page 3\n",
      "[INFO] (4/29) Page 4\n",
      "[INFO] (5/29) Page 5\n",
      "[INFO] (6/29) Page 6\n",
      "[INFO] (7/29) Page 7\n",
      "[INFO] (8/29) Page 8\n",
      "[INFO] (9/29) Page 9\n",
      "[INFO] (10/29) Page 10\n",
      "[INFO] (11/29) Page 11\n",
      "[INFO] (12/29) Page 12\n",
      "[INFO] (13/29) Page 13\n",
      "[INFO] (14/29) Page 14\n",
      "[INFO] (15/29) Page 15\n",
      "[INFO] (16/29) Page 16\n",
      "[INFO] (17/29) Page 17\n",
      "[INFO] (18/29) Page 18\n",
      "[INFO] (19/29) Page 19\n",
      "[INFO] (20/29) Page 20\n",
      "[INFO] (21/29) Page 21\n",
      "[INFO] (22/29) Page 22\n",
      "[INFO] (23/29) Page 23\n",
      "[INFO] (24/29) Page 24\n",
      "[INFO] (25/29) Page 25\n",
      "[INFO] (26/29) Page 26\n",
      "[INFO] (27/29) Page 27\n",
      "[INFO] (28/29) Page 28\n",
      "[INFO] (29/29) Page 29\n",
      "[INFO] Terminated in 4.16s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\17-YonBIP旗舰版专业开发-开发指南-扩展开发-基于特征的标准产品扩展开发.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 16-YonBIP旗舰版专业开发-开发指南-成果迁移-开发成果迁移（R6）.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\16-YonBIP旗舰版专业开发-开发指南-成果迁移-开发成果迁移（R6）.docx\n",
      "Converting 17-YonBIP旗舰版专业开发-开发指南-扩展开发-基于特征的标准产品扩展开发.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/61) Page 1\n",
      "[INFO] (2/61) Page 2\n",
      "[INFO] (3/61) Page 3\n",
      "[INFO] (4/61) Page 4\n",
      "[INFO] (5/61) Page 5\n",
      "[INFO] (6/61) Page 6\n",
      "[INFO] (7/61) Page 7\n",
      "[INFO] (8/61) Page 8\n",
      "[INFO] (9/61) Page 9\n",
      "[INFO] (10/61) Page 10\n",
      "[INFO] (11/61) Page 11\n",
      "[INFO] (12/61) Page 12\n",
      "[INFO] (13/61) Page 13\n",
      "[INFO] (14/61) Page 14\n",
      "[INFO] (15/61) Page 15\n",
      "[INFO] (16/61) Page 16\n",
      "[INFO] (17/61) Page 17\n",
      "[INFO] (18/61) Page 18\n",
      "[INFO] (19/61) Page 19\n",
      "[INFO] (20/61) Page 20\n",
      "[INFO] (21/61) Page 21\n",
      "[INFO] (22/61) Page 22\n",
      "[INFO] (23/61) Page 23\n",
      "[INFO] (24/61) Page 24\n",
      "[INFO] (25/61) Page 25\n",
      "[INFO] (26/61) Page 26\n",
      "[INFO] (27/61) Page 27\n",
      "[INFO] (28/61) Page 28\n",
      "[INFO] (29/61) Page 29\n",
      "[INFO] (30/61) Page 30\n",
      "[INFO] (31/61) Page 31\n",
      "[INFO] (32/61) Page 32\n",
      "[INFO] (33/61) Page 33\n",
      "[INFO] (34/61) Page 34\n",
      "[INFO] (35/61) Page 35\n",
      "[INFO] (36/61) Page 36\n",
      "[INFO] (37/61) Page 37\n",
      "[INFO] (38/61) Page 38\n",
      "[INFO] (39/61) Page 39\n",
      "[INFO] (40/61) Page 40\n",
      "[INFO] (41/61) Page 41\n",
      "[INFO] (42/61) Page 42\n",
      "[INFO] (43/61) Page 43\n",
      "[INFO] (44/61) Page 44\n",
      "[INFO] (45/61) Page 45\n",
      "[INFO] (46/61) Page 46\n",
      "[INFO] (47/61) Page 47\n",
      "[INFO] (48/61) Page 48\n",
      "[INFO] (49/61) Page 49\n",
      "[INFO] (50/61) Page 50\n",
      "[INFO] (51/61) Page 51\n",
      "[INFO] (52/61) Page 52\n",
      "[INFO] (53/61) Page 53\n",
      "[INFO] (54/61) Page 54\n",
      "[INFO] (55/61) Page 55\n",
      "[INFO] (56/61) Page 56\n",
      "[INFO] (57/61) Page 57\n",
      "[INFO] (58/61) Page 58\n",
      "[INFO] (59/61) Page 59\n",
      "[INFO] (60/61) Page 60\n",
      "[INFO] (61/61) Page 61\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/61) Page 1\n",
      "[INFO] (2/61) Page 2\n",
      "[INFO] (3/61) Page 3\n",
      "[INFO] (4/61) Page 4\n",
      "[INFO] (5/61) Page 5\n",
      "[INFO] (6/61) Page 6\n",
      "[INFO] (7/61) Page 7\n",
      "[INFO] (8/61) Page 8\n",
      "[INFO] (9/61) Page 9\n",
      "[INFO] (10/61) Page 10\n",
      "[INFO] (11/61) Page 11\n",
      "[INFO] (12/61) Page 12\n",
      "[INFO] (13/61) Page 13\n",
      "[INFO] (14/61) Page 14\n",
      "[INFO] (15/61) Page 15\n",
      "[INFO] (16/61) Page 16\n",
      "[INFO] (17/61) Page 17\n",
      "[INFO] (18/61) Page 18\n",
      "[INFO] (19/61) Page 19\n",
      "[INFO] (20/61) Page 20\n",
      "[INFO] (21/61) Page 21\n",
      "[INFO] (22/61) Page 22\n",
      "[INFO] (23/61) Page 23\n",
      "[INFO] (24/61) Page 24\n",
      "[INFO] (25/61) Page 25\n",
      "[INFO] (26/61) Page 26\n",
      "[INFO] (27/61) Page 27\n",
      "[INFO] (28/61) Page 28\n",
      "[INFO] (29/61) Page 29\n",
      "[INFO] (30/61) Page 30\n",
      "[INFO] (31/61) Page 31\n",
      "[INFO] (32/61) Page 32\n",
      "[INFO] (33/61) Page 33\n",
      "[INFO] (34/61) Page 34\n",
      "[INFO] (35/61) Page 35\n",
      "[INFO] (36/61) Page 36\n",
      "[INFO] (37/61) Page 37\n",
      "[INFO] (38/61) Page 38\n",
      "[INFO] (39/61) Page 39\n",
      "[INFO] (40/61) Page 40\n",
      "[INFO] (41/61) Page 41\n",
      "[INFO] (42/61) Page 42\n",
      "[INFO] (43/61) Page 43\n",
      "[INFO] (44/61) Page 44\n",
      "[INFO] (45/61) Page 45\n",
      "[INFO] (46/61) Page 46\n",
      "[INFO] (47/61) Page 47\n",
      "[INFO] (48/61) Page 48\n",
      "[INFO] (49/61) Page 49\n",
      "[INFO] (50/61) Page 50\n",
      "[INFO] (51/61) Page 51\n",
      "[INFO] (52/61) Page 52\n",
      "[INFO] (53/61) Page 53\n",
      "[INFO] (54/61) Page 54\n",
      "[INFO] (55/61) Page 55\n",
      "[INFO] (56/61) Page 56\n",
      "[INFO] (57/61) Page 57\n",
      "[INFO] (58/61) Page 58\n",
      "[INFO] (59/61) Page 59\n",
      "[INFO] (60/61) Page 60\n",
      "[INFO] (61/61) Page 61\n",
      "[INFO] Terminated in 8.17s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\18-YonBIP旗舰版专业开发-开发指南-扩展开发-扩展开发介绍.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 17-YonBIP旗舰版专业开发-开发指南-扩展开发-基于特征的标准产品扩展开发.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\17-YonBIP旗舰版专业开发-开发指南-扩展开发-基于特征的标准产品扩展开发.docx\n",
      "Converting 18-YonBIP旗舰版专业开发-开发指南-扩展开发-扩展开发介绍.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/51) Page 1\n",
      "[INFO] (2/51) Page 2\n",
      "[INFO] (3/51) Page 3\n",
      "[INFO] (4/51) Page 4\n",
      "[INFO] (5/51) Page 5\n",
      "[INFO] (6/51) Page 6\n",
      "[INFO] (7/51) Page 7\n",
      "[INFO] (8/51) Page 8\n",
      "[INFO] (9/51) Page 9\n",
      "[INFO] (10/51) Page 10\n",
      "[INFO] (11/51) Page 11\n",
      "[INFO] (12/51) Page 12\n",
      "[INFO] (13/51) Page 13\n",
      "[INFO] (14/51) Page 14\n",
      "[INFO] (15/51) Page 15\n",
      "[INFO] (16/51) Page 16\n",
      "[INFO] (17/51) Page 17\n",
      "[INFO] (18/51) Page 18\n",
      "[INFO] (19/51) Page 19\n",
      "[INFO] (20/51) Page 20\n",
      "[INFO] (21/51) Page 21\n",
      "[INFO] (22/51) Page 22\n",
      "[INFO] (23/51) Page 23\n",
      "[INFO] (24/51) Page 24\n",
      "[INFO] (25/51) Page 25\n",
      "[INFO] (26/51) Page 26\n",
      "[INFO] (27/51) Page 27\n",
      "[INFO] (28/51) Page 28\n",
      "[INFO] (29/51) Page 29\n",
      "[INFO] (30/51) Page 30\n",
      "[INFO] (31/51) Page 31\n",
      "[INFO] (32/51) Page 32\n",
      "[INFO] (33/51) Page 33\n",
      "[INFO] (34/51) Page 34\n",
      "[INFO] (35/51) Page 35\n",
      "[INFO] (36/51) Page 36\n",
      "[INFO] (37/51) Page 37\n",
      "[INFO] (38/51) Page 38\n",
      "[INFO] (39/51) Page 39\n",
      "[INFO] (40/51) Page 40\n",
      "[INFO] (41/51) Page 41\n",
      "[INFO] (42/51) Page 42\n",
      "[INFO] (43/51) Page 43\n",
      "[INFO] (44/51) Page 44\n",
      "[INFO] (45/51) Page 45\n",
      "[INFO] (46/51) Page 46\n",
      "[INFO] (47/51) Page 47\n",
      "[INFO] (48/51) Page 48\n",
      "[INFO] (49/51) Page 49\n",
      "[INFO] (50/51) Page 50\n",
      "[INFO] (51/51) Page 51\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/51) Page 1\n",
      "[INFO] (2/51) Page 2\n",
      "[INFO] (3/51) Page 3\n",
      "[INFO] (4/51) Page 4\n",
      "[INFO] (5/51) Page 5\n",
      "[INFO] (6/51) Page 6\n",
      "[INFO] (7/51) Page 7\n",
      "[INFO] (8/51) Page 8\n",
      "[INFO] (9/51) Page 9\n",
      "[INFO] (10/51) Page 10\n",
      "[INFO] (11/51) Page 11\n",
      "[INFO] (12/51) Page 12\n",
      "[INFO] (13/51) Page 13\n",
      "[INFO] (14/51) Page 14\n",
      "[INFO] (15/51) Page 15\n",
      "[INFO] (16/51) Page 16\n",
      "[INFO] (17/51) Page 17\n",
      "[INFO] (18/51) Page 18\n",
      "[INFO] (19/51) Page 19\n",
      "[INFO] (20/51) Page 20\n",
      "[INFO] (21/51) Page 21\n",
      "[INFO] (22/51) Page 22\n",
      "[INFO] (23/51) Page 23\n",
      "[INFO] (24/51) Page 24\n",
      "[INFO] (25/51) Page 25\n",
      "[INFO] (26/51) Page 26\n",
      "[INFO] (27/51) Page 27\n",
      "[INFO] (28/51) Page 28\n",
      "[INFO] (29/51) Page 29\n",
      "[INFO] (30/51) Page 30\n",
      "[INFO] (31/51) Page 31\n",
      "[INFO] (32/51) Page 32\n",
      "[INFO] (33/51) Page 33\n",
      "[INFO] (34/51) Page 34\n",
      "[INFO] (35/51) Page 35\n",
      "[INFO] (36/51) Page 36\n",
      "[INFO] (37/51) Page 37\n",
      "[INFO] (38/51) Page 38\n",
      "[INFO] (39/51) Page 39\n",
      "[INFO] (40/51) Page 40\n",
      "[INFO] (41/51) Page 41\n",
      "[INFO] (42/51) Page 42\n",
      "[INFO] (43/51) Page 43\n",
      "[INFO] (44/51) Page 44\n",
      "[INFO] (45/51) Page 45\n",
      "[INFO] (46/51) Page 46\n",
      "[INFO] (47/51) Page 47\n",
      "[INFO] (48/51) Page 48\n",
      "[INFO] (49/51) Page 49\n",
      "[INFO] (50/51) Page 50\n",
      "[INFO] (51/51) Page 51\n",
      "[INFO] Terminated in 465.60s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\23-YonBIP旗舰版专业开发-开发指南-移动端开发-组件扩展开发.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 18-YonBIP旗舰版专业开发-开发指南-扩展开发-扩展开发介绍.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\18-YonBIP旗舰版专业开发-开发指南-扩展开发-扩展开发介绍.docx\n",
      "Converting 23-YonBIP旗舰版专业开发-开发指南-移动端开发-组件扩展开发.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/28) Page 1\n",
      "[INFO] (2/28) Page 2\n",
      "[INFO] (3/28) Page 3\n",
      "[INFO] (4/28) Page 4\n",
      "[INFO] (5/28) Page 5\n",
      "[INFO] (6/28) Page 6\n",
      "[INFO] (7/28) Page 7\n",
      "[INFO] (8/28) Page 8\n",
      "[INFO] (9/28) Page 9\n",
      "[INFO] (10/28) Page 10\n",
      "[INFO] (11/28) Page 11\n",
      "[INFO] (12/28) Page 12\n",
      "[INFO] (13/28) Page 13\n",
      "[INFO] (14/28) Page 14\n",
      "[INFO] (15/28) Page 15\n",
      "[INFO] (16/28) Page 16\n",
      "[INFO] (17/28) Page 17\n",
      "[INFO] (18/28) Page 18\n",
      "[INFO] (19/28) Page 19\n",
      "[INFO] (20/28) Page 20\n",
      "[INFO] (21/28) Page 21\n",
      "[INFO] (22/28) Page 22\n",
      "[INFO] (23/28) Page 23\n",
      "[INFO] (24/28) Page 24\n",
      "[INFO] (25/28) Page 25\n",
      "[INFO] (26/28) Page 26\n",
      "[INFO] (27/28) Page 27\n",
      "[INFO] (28/28) Page 28\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/28) Page 1\n",
      "[INFO] (2/28) Page 2\n",
      "[INFO] (3/28) Page 3\n",
      "[INFO] (4/28) Page 4\n",
      "[INFO] (5/28) Page 5\n",
      "[INFO] (6/28) Page 6\n",
      "[INFO] (7/28) Page 7\n",
      "[INFO] (8/28) Page 8\n",
      "[INFO] (9/28) Page 9\n",
      "[INFO] (10/28) Page 10\n",
      "[INFO] (11/28) Page 11\n",
      "[INFO] (12/28) Page 12\n",
      "[INFO] (13/28) Page 13\n",
      "[INFO] (14/28) Page 14\n",
      "[INFO] (15/28) Page 15\n",
      "[INFO] (16/28) Page 16\n",
      "[INFO] (17/28) Page 17\n",
      "[INFO] (18/28) Page 18\n",
      "[INFO] (19/28) Page 19\n",
      "[INFO] (20/28) Page 20\n",
      "[INFO] (21/28) Page 21\n",
      "[INFO] (22/28) Page 22\n",
      "[INFO] (23/28) Page 23\n",
      "[INFO] (24/28) Page 24\n",
      "[INFO] (25/28) Page 25\n",
      "[INFO] (26/28) Page 26\n",
      "[INFO] (27/28) Page 27\n",
      "[INFO] (28/28) Page 28\n",
      "[INFO] Terminated in 4.55s.\n",
      "[INFO] Start to convert C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\24-YonBIP旗舰版专业开发-开发指南-移动端开发-打包.pdf\n",
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 23-YonBIP旗舰版专业开发-开发指南-移动端开发-组件扩展开发.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\23-YonBIP旗舰版专业开发-开发指南-移动端开发-组件扩展开发.docx\n",
      "Converting 24-YonBIP旗舰版专业开发-开发指南-移动端开发-打包.pdf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/30) Page 1\n",
      "[INFO] (2/30) Page 2\n",
      "[INFO] (3/30) Page 3\n",
      "[INFO] (4/30) Page 4\n",
      "[INFO] (5/30) Page 5\n",
      "[INFO] (6/30) Page 6\n",
      "[INFO] (7/30) Page 7\n",
      "[INFO] (8/30) Page 8\n",
      "[INFO] (9/30) Page 9\n",
      "[INFO] (10/30) Page 10\n",
      "[INFO] (11/30) Page 11\n",
      "[INFO] (12/30) Page 12\n",
      "[INFO] (13/30) Page 13\n",
      "[INFO] (14/30) Page 14\n",
      "[INFO] (15/30) Page 15\n",
      "[INFO] (16/30) Page 16\n",
      "[INFO] (17/30) Page 17\n",
      "[INFO] (18/30) Page 18\n",
      "[INFO] (19/30) Page 19\n",
      "[INFO] (20/30) Page 20\n",
      "[INFO] (21/30) Page 21\n",
      "[INFO] (22/30) Page 22\n",
      "[INFO] (23/30) Page 23\n",
      "[INFO] (24/30) Page 24\n",
      "[INFO] (25/30) Page 25\n",
      "[INFO] (26/30) Page 26\n",
      "[INFO] (27/30) Page 27\n",
      "[INFO] (28/30) Page 28\n",
      "[INFO] (29/30) Page 29\n",
      "[INFO] (30/30) Page 30\n",
      "[INFO] \u001b[1;36m[4/4] Creating pages...\u001b[0m\n",
      "[INFO] (1/30) Page 1\n",
      "[INFO] (2/30) Page 2\n",
      "[INFO] (3/30) Page 3\n",
      "[INFO] (4/30) Page 4\n",
      "[INFO] (5/30) Page 5\n",
      "[INFO] (6/30) Page 6\n",
      "[INFO] (7/30) Page 7\n",
      "[INFO] (8/30) Page 8\n",
      "[INFO] (9/30) Page 9\n",
      "[INFO] (10/30) Page 10\n",
      "[INFO] (11/30) Page 11\n",
      "[INFO] (12/30) Page 12\n",
      "[INFO] (13/30) Page 13\n",
      "[INFO] (14/30) Page 14\n",
      "[INFO] (15/30) Page 15\n",
      "[INFO] (16/30) Page 16\n",
      "[INFO] (17/30) Page 17\n",
      "[INFO] (18/30) Page 18\n",
      "[INFO] (19/30) Page 19\n",
      "[INFO] (20/30) Page 20\n",
      "[INFO] (21/30) Page 21\n",
      "[INFO] (22/30) Page 22\n",
      "[INFO] (23/30) Page 23\n",
      "[INFO] (24/30) Page 24\n",
      "[INFO] (25/30) Page 25\n",
      "[INFO] (26/30) Page 26\n",
      "[INFO] (27/30) Page 27\n",
      "[INFO] (28/30) Page 28\n",
      "[INFO] (29/30) Page 29\n",
      "[INFO] (30/30) Page 30\n",
      "[INFO] Terminated in 4.11s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted: 24-YonBIP旗舰版专业开发-开发指南-移动端开发-打包.pdf -> C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\\24-YonBIP旗舰版专业开发-开发指南-移动端开发-打包.docx\n",
      "All files have been processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdf2docx import Converter\n",
    "\n",
    "def convert_pdf_folder_to_docx(input_folder, output_folder):\n",
    "    # 创建输出文件夹（如果不存在）\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 遍历输入文件夹中的所有 PDF 文件\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith('.pdf'):\n",
    "            pdf_file = os.path.join(input_folder, filename)\n",
    "            docx_file = os.path.join(output_folder, filename.replace('.pdf', '.docx'))\n",
    "            \n",
    "            # 转换 PDF 为 DOCX\n",
    "            print(f\"Converting {filename}...\")\n",
    "            try:\n",
    "                cv = Converter(pdf_file)\n",
    "                cv.convert(docx_file)\n",
    "                cv.close()\n",
    "                print(f\"Successfully converted: {filename} -> {docx_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {filename}: {e}\")\n",
    "\n",
    "    print(\"All files have been processed.\")\n",
    "\n",
    "# 输入 PDF 文件夹路径和输出 DOCX 文件夹路径\n",
    "input_folder = r\"C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\"  # 替换为你的 PDF 文件夹路径\n",
    "output_folder = r\"C:\\Users\\wangz\\Downloads\\万华项目文档-刘坤林\\02-24客开赋能\"  # 替换为输出 DOCX 的文件夹路径\n",
    "\n",
    "# 执行转换\n",
    "convert_pdf_folder_to_docx(input_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
