{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 100000/100000 [1:33:06<00:00, 17.90it/s]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_3_translated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 100000/100000 [26:43<00:00, 62.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_4_translated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 100000/100000 [25:51<00:00, 64.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_5_translated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 100000/100000 [28:17<00:00, 58.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_6_translated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 100000/100000 [31:31<00:00, 52.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_7_translated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 100000/100000 [30:43<00:00, 54.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_8_translated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 100000/100000 [29:10<00:00, 57.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_9_translated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 100000/100000 [29:30<00:00, 56.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_10_translated.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 30626/30626 [16:38<00:00, 30.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "翻译结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_11_translated.xlsx\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 辅助函数：根据术语库查找翻译\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def find_translations(input_text, original_language, target_language, glossary_df):\n",
    "    # 如果 original_language 或 target_language 不是列名，则直接返回空列表\n",
    "    if original_language not in glossary_df.columns or target_language not in glossary_df.columns:\n",
    "        return []\n",
    "    \n",
    "    # 过滤掉原始术语为空的行，使用向量化方法构建字典\n",
    "    valid_entries = glossary_df[glossary_df[original_language].notna()]\n",
    "    term_dict = dict(zip(valid_entries[original_language], valid_entries[target_language]))\n",
    "    \n",
    "    # 构建正则表达式，利用 re.escape 对每个术语转义，再用 \"|\" 拼接起来\n",
    "    # 这样可以一次性匹配所有术语\n",
    "    pattern = re.compile(\"|\".join(map(re.escape, term_dict.keys())))\n",
    "    \n",
    "    # 使用正则表达式查找所有匹配项，结果可能包含重复匹配\n",
    "    found_terms = set(pattern.findall(input_text))\n",
    "    \n",
    "    # 根据匹配到的术语，构造结果列表\n",
    "    results = [(term, term_dict[term]) for term in found_terms]\n",
    "    return results\n",
    "\n",
    "\n",
    "# 辅助函数：检测文本中是否包含特殊字符串\n",
    "def contains_special_string(sentence):\n",
    "    patterns = {\n",
    "        \"<% ... %>\": r\"<%.*?%>\",\n",
    "        \"%s\": r\"%s\",\n",
    "        \"{0}, {1}, {2} 等\": r\"{\\d+}\",\n",
    "        \"%d\": r\"%d\",\n",
    "        \"{counts}\": r\"{counts}\",\n",
    "        \"&{...}&\": r\"&{.*?}&\",\n",
    "        \"{}\": r\"{}\",\n",
    "        \"#...#\": r\"#.*?#\",\n",
    "        \"{{...}}\": r\"{{.*?}}\",\n",
    "        \"连续的大写英文字母（AR, AP, SKU）\": r\"[A-Z]{2,}\",\n",
    "        \"大驼峰命名的单词（如 ServiceCode, LocStudio）\": r\"(?:[A-Z][a-z]+){2,}\",\n",
    "        \"包含 http:// 的字符串\": r\"http://\",\n",
    "        \"包含 https:// 的字符串\": r\"https://\",\n",
    "        \"包含 E:\\\\, D:\\\\, C:\\\\ 的字符串\": r\"[CDE]:\\\\\",\n",
    "        \"包含 datediff(.*?,.*?,.*?) 的字符串\": r\"datediff\\(.*?,.*?,.*?\\)\",\n",
    "        \"@业务函数. ... 的字符串@\": r\"@业务函数\\..*?@\",\n",
    "        \"小驼峰命名的单词（如 serviceCode, locStudio）\": r\"[a-z]+[a-z]*[A-Z][a-zA-Z]*\"\n",
    "    }\n",
    "\n",
    "    reasons = []\n",
    "    matched_strings = []\n",
    "    for reason, pattern in patterns.items():\n",
    "        matches = re.findall(pattern, sentence)\n",
    "        if matches:\n",
    "            reasons.append(reason)\n",
    "            matched_strings.extend(matches)\n",
    "    return {\n",
    "        \"contains_special_string\": bool(reasons),\n",
    "        \"reason\": reasons,\n",
    "        \"matched_strings\": matched_strings\n",
    "    }\n",
    "\n",
    "# 定义 Model 类\n",
    "class Model():\n",
    "    def __init__(self, modelname, selected_lora_model, selected_gpu, glossary_df):\n",
    "        self.client = OpenAI()\n",
    "        self.glossary_df = glossary_df\n",
    "\n",
    "    def translate_section(self, input_text, original_language, target_languages):\n",
    "        res = []\n",
    "        for target_language in target_languages:\n",
    "            # 特殊情况：若文本以特定标识开头、或者文本不含中英文字符、或者文本为特定标记，则直接返回原文\n",
    "            if input_text.strip().startswith(\"[ref1]\") or \\\n",
    "               not re.search(r'[A-Za-z\\u4e00-\\u9fff]', input_text.strip()) or \\\n",
    "               input_text.strip() in [\"此词条确认无需翻译或已废弃\", \"!!!!!!!!\", \"Obsolete\", \"obsolete\"]:\n",
    "                res.append({\n",
    "                    \"target_language\": target_language,\n",
    "                    \"generated_translation\": input_text,\n",
    "                    \"geo_mean_confidence\": 1\n",
    "                })\n",
    "            else:\n",
    "                # 提取并暂时移除 markdown 中的图片（base64格式）\n",
    "                removed_images = re.findall(r\"!\\[.*?\\]\\(data:image\\/[^;]+;base64,[^)]+\\)\", input_text)\n",
    "                input_text_clean = re.sub(r\"!\\[.*?\\]\\(data:image\\/[^;]+;base64,[^)]+\\)\", \"\", input_text)\n",
    "\n",
    "                # 查找术语翻译\n",
    "                matches = find_translations(input_text_clean, original_language, target_language, self.glossary_df)\n",
    "                if matches:\n",
    "                    terminology_guide = \"\\n\".join([f\"- {item1}: {item2}\" for item1, item2 in matches])\n",
    "                    system_prompt = f\"\"\"\n",
    "You are an expert in translating {original_language} to {target_language} for ERP systems. Your task is to translate markdown-formatted text from {original_language} to {target_language}.\n",
    "\n",
    "Here is a terminology guide to help you ensure accurate translations for common ERP terms:\n",
    "{terminology_guide}\n",
    "\n",
    "The text to be translated may not necessarily be complete phrases or sentences, but you must translate it into the corresponding language based on your understanding while preserving its formatting.\n",
    "\"\"\"\n",
    "                else:\n",
    "                    system_prompt = f\"\"\"\n",
    "You are an expert in translating {original_language} to {target_language} for ERP systems. Your task is to translate markdown-formatted text from {original_language} to {target_language}.\n",
    "\n",
    "The text to be translated may not necessarily be complete phrases or sentences, but you must translate it into the corresponding language based on your understanding while preserving its formatting.\n",
    "\"\"\"\n",
    "\n",
    "                messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "                special_string_list = []\n",
    "                for i in range(2):\n",
    "                    if i == 0:\n",
    "                        messages.append({\"role\": \"user\", \"content\": input_text_clean})\n",
    "                    else:\n",
    "                        messages.append({\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"You should skip the words: {', '.join(special_string_list)}. Do not translate these words. Please translate again without adding extra content.\"\n",
    "                        })\n",
    "\n",
    "                    completion = self.client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        messages=messages,\n",
    "                        temperature=0,\n",
    "                        logprobs=True,\n",
    "                        top_p=1\n",
    "                    )\n",
    "                    translated_text = completion.choices[0].message.content\n",
    "                    logprobs = [token.logprob for token in completion.choices[0].logprobs.content]\n",
    "                    probs = np.exp(logprobs)\n",
    "                    geo_mean_confidence = float(np.prod(probs) ** (1 / len(probs)))\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": translated_text})\n",
    "\n",
    "                    # 检查错误信息\n",
    "                    error_messages = [\n",
    "                        \"Sorry, I can't assist with that request\",\n",
    "                        \"It seems like your message is incomplete\"\n",
    "                    ]\n",
    "                    if any(error_msg in translated_text for error_msg in error_messages):\n",
    "                        continue\n",
    "\n",
    "                    temp = contains_special_string(input_text_clean)\n",
    "                    if temp[\"contains_special_string\"]:\n",
    "                        all_special_strings_retained = True\n",
    "                        for matched_string in temp[\"matched_strings\"]:\n",
    "                            if matched_string not in translated_text:\n",
    "                                all_special_strings_retained = False\n",
    "                                if matched_string not in special_string_list:\n",
    "                                    special_string_list.append(matched_string)\n",
    "                        if all_special_strings_retained:\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                if removed_images:\n",
    "                    translated_text += \"\\n\" + \"\\n\".join(removed_images)\n",
    "\n",
    "                translated_text = re.sub(r'[\\u4e00-\\u9fff]', '', translated_text)\n",
    "                res.append({\n",
    "                    \"target_language\": target_language,\n",
    "                    \"generated_translation\": translated_text,\n",
    "                    \"geo_mean_confidence\": geo_mean_confidence\n",
    "                })\n",
    "        return res\n",
    "\n",
    "    # 使用多线程批量翻译多个文本，同时显示进度条\n",
    "    def generate(self, inputs, original_language, target_languages, max_workers=2000):\n",
    "        res = [None] * len(inputs)\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {executor.submit(self.translate_section, inputs[i], original_language, target_languages): i for i in range(len(inputs))}\n",
    "            # 用 tqdm 包裹 as_completed 迭代器，显示进度\n",
    "            for future in tqdm(as_completed(futures), total=len(futures), desc=\"Translating\"):\n",
    "                index = futures[future]\n",
    "                try:\n",
    "                    res[index] = future.result()\n",
    "                except Exception as e:\n",
    "                    res[index] = [{\"target_language\": target_language, \"generated_translation\": f\"Error: {e}\", \"geo_mean_confidence\": 0} \n",
    "                                  for target_language in target_languages]\n",
    "        return res\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 参数设置\n",
    "    original_col = \"简体中文(源)\"  # 待翻译文本所在列\n",
    "    target_col = \"待翻译(译)\"      # 翻译后文本存放列\n",
    "    conf_col = \"备注\"            # 存放置信度的列\n",
    "    original_language = \"Chinese\"\n",
    "    target_language = \"Thai\"\n",
    "\n",
    "    # 读取术语库\n",
    "    glossary_file = r\"glossary.xlsx\"\n",
    "    glossary_df = pd.read_excel(glossary_file)\n",
    "\n",
    "    # 实例化 Model 对象\n",
    "    model = Model(\"gpt-4o-mini\", selected_lora_model=None, selected_gpu=None, glossary_df=glossary_df)\n",
    "\n",
    "    # 循环处理 part_3 到 part_11 的文件\n",
    "    for part in range(3, 12):\n",
    "        input_excel = f\"D:\\\\Projects\\\\ai-translator\\\\src\\\\multilangInitData20250210空\\\\part_{part}.xlsx\"\n",
    "        output_excel = f\"D:\\\\Projects\\\\ai-translator\\\\src\\\\multilangInitData20250210空\\\\part_{part}_translated.xlsx\"\n",
    "        df = pd.read_excel(input_excel)\n",
    "        inputs = df[original_col].astype(str).tolist()\n",
    "        translation_results = model.generate(inputs, original_language, [target_language], max_workers=200)\n",
    "        \n",
    "        translated_texts = []\n",
    "        confidences = []\n",
    "        for result in translation_results:\n",
    "            if result and isinstance(result, list) and len(result) > 0:\n",
    "                d = result[0]\n",
    "                translated_texts.append(d.get(\"generated_translation\", \"\"))\n",
    "                confidences.append(d.get(\"geo_mean_confidence\", 0))\n",
    "            else:\n",
    "                translated_texts.append(\"\")\n",
    "                confidences.append(0)\n",
    "        \n",
    "        df[target_col] = translated_texts\n",
    "        df[conf_col] = confidences\n",
    "        df.to_excel(output_excel, index=False)\n",
    "        print(f\"翻译结果已保存到 {output_excel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，结果已保存到 D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_1_translated.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 定义文件路径\n",
    "input_file = r\"D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_1_translated.xlsx\"\n",
    "output_file = r\"D:\\Projects\\ai-translator\\src\\multilangInitData20250210空\\part_1_translated.xlsx\"\n",
    "\n",
    "# 读取 Excel 文件\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# 删除 \"待翻译(译)\" 列中所有中文字符（Unicode 范围：\\u4e00 - \\u9fff）\n",
    "df[\"待翻译(译)\"] = df[\"待翻译(译)\"].astype(str).apply(lambda x: re.sub(r'[\\u4e00-\\u9fff]', '', x))\n",
    "\n",
    "# 保存结果到新的 Excel 文件\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"处理完成，结果已保存到 {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
